version: '3.8'

services:
  # PostgreSQL with pgvector extension
  postgres:
    image: ankane/pgvector:latest
    container_name: f5-flowise-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: flowise
      POSTGRES_USER: flowise
      POSTGRES_PASSWORD: flowisepassword
    ports:
      - '5433:5432'  # Changed to 5433 to avoid conflict with local PostgreSQL
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U flowise']
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - flowise_network

  # Ollama for local LLM inference
  ollama:
    image: ollama/ollama:latest
    container_name: f5-flowise-ollama
    restart: unless-stopped
    ports:
      - '11435:11434'  # Changed to avoid conflict with local Ollama
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - flowise_network

  # Ollama model initialization - pulls embedding model on startup
  ollama-pull-models:
    image: curlimages/curl:latest
    container_name: f5-flowise-ollama-init
    depends_on:
      - ollama
    networks:
      - flowise_network
    entrypoint: /bin/sh
    command:
      - -c
      - |
        echo "Waiting for Ollama service to be ready..."
        max_attempts=30
        attempt=0

        while [ $$attempt -lt $$max_attempts ]; do
          if curl -s http://ollama:11434/api/tags > /dev/null 2>&1; then
            echo "Ollama is ready! Response received from http://ollama:11434/api/tags"
            break
          fi
          attempt=$$((attempt + 1))
          echo "Attempt $$attempt/$$max_attempts: Ollama not ready yet, waiting..."
          sleep 2
        done

        if [ $$attempt -eq $$max_attempts ]; then
          echo "ERROR: Ollama did not respond after $$max_attempts attempts"
          exit 1
        fi

        echo "Installing ollama client and pulling embedding model..."
        apk add --no-cache curl

        # Use curl to trigger model pull via Ollama API
        echo "Pulling nomic-embed-text embedding model via API..."
        curl -X POST http://ollama:11434/api/pull -d '{"name":"nomic-embed-text"}' || exit 1

        echo "Embedding model installation complete!"
    restart: "no"

  # Flowise application (F5-branded)
  flowise:
    build:
      context: .
      dockerfile: Dockerfile
    image: f5-flowise:latest
    container_name: f5-flowise-app
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    environment:
      # Application
      - PORT=3000
      - NODE_ENV=production

      # PostgreSQL Database Configuration
      - DATABASE_TYPE=postgres
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_NAME=flowise
      - DATABASE_USER=flowise
      - DATABASE_PASSWORD=flowisepassword

      # Paths
      - APIKEY_PATH=/root/.flowise
      - SECRETKEY_PATH=/root/.flowise
      - LOG_PATH=/root/.flowise/logs
      - BLOB_STORAGE_PATH=/root/.flowise/storage

      # Optional: Uncomment to enable authentication
      # - FLOWISE_USERNAME=admin
      # - FLOWISE_PASSWORD=changeme

      # Optional: Uncomment to configure CORS
      # - CORS_ORIGINS=*
      # - IFRAME_ORIGINS=*
    ports:
      - '3001:3000'  # Changed to avoid port conflict
    volumes:
      - flowise_data:/root/.flowise
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:3000/api/v1/ping']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - flowise_network

volumes:
  postgres_data:
    driver: local
    name: f5_postgres_data
  ollama_data:
    driver: local
    name: f5_ollama_data
  flowise_data:
    driver: local
    name: f5_flowise_data

# Shared network for all F5 Flowise services
# This allows containers to communicate with each other using service names
networks:
  flowise_network:
    driver: bridge
    name: f5_flowise_network
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.0.1
